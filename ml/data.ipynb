{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1933238/3515626404.py:6: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  import tqdm.autonotebook as tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "import tqdm.autonotebook as tqdm\n",
    "\n",
    "GITHUB_API_URL = \"https://api.github.com\"\n",
    "PER_PAGE = 100\n",
    "MAX_SIZE_KB = 40000\n",
    "\n",
    "TOKEN = '???'\n",
    "\n",
    "HEADERS = {\n",
    "    'Authorization': f'token {TOKEN}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "def get_repositories_for_language(language, limit=10):\n",
    "    repos = []\n",
    "    page = 1\n",
    "    while len(repos) < limit:\n",
    "        l = f'\"{language}\"'\n",
    "        response = requests.get(f\"{GITHUB_API_URL}/search/repositories?q=language:{l}&per_page={PER_PAGE}&page={page}\", headers=HEADERS)\n",
    "        items = response.json().get('items', [])\n",
    "        if not items:\n",
    "            break\n",
    "        repos.extend(items[:limit - len(repos)])\n",
    "        page += 1\n",
    "    return repos\n",
    "\n",
    "def get_repositories_for_query(language, limit=10):\n",
    "    repos = []\n",
    "    page = 1\n",
    "    while len(repos) < limit:\n",
    "\n",
    "        l = f'{language}'\n",
    "        response = requests.get(f\"{GITHUB_API_URL}/search/repositories?q={l}&per_page={PER_PAGE}&page={page}\", headers=HEADERS)\n",
    "        items = response.json().get('items', [])\n",
    "        if not items:\n",
    "            break\n",
    "        repos.extend(items[:limit - len(repos)])\n",
    "        page += 1\n",
    "    return repos\n",
    "\n",
    "def clone_and_process_repo(repo, language, extensions):\n",
    "    author, repo_name = repo['full_name'].split('/')\n",
    "    clone_dest_folder = os.path.join('downloaded_repos', language, author, repo_name)\n",
    "    files_dest_folder = os.path.join('downloaded_files', language, author, repo_name)\n",
    "\n",
    "    if repo['size'] > MAX_SIZE_KB:\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(clone_dest_folder):\n",
    "        subprocess.run(['git', 'clone', repo['clone_url'], clone_dest_folder], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    for root, dirs, files in os.walk(clone_dest_folder):\n",
    "        for filename in files:\n",
    "            if any(filename.lower().endswith(f\"{ext.lower()}\") for ext in extensions):\n",
    "                source_filepath = os.path.join(root, filename)\n",
    "                dest_filepath = os.path.join(files_dest_folder, filename)\n",
    "                os.makedirs(os.path.dirname(dest_filepath), exist_ok=True)\n",
    "                if os.path.exists(dest_filepath):\n",
    "                    basename = os.path.basename(dest_filepath)\n",
    "                    basename, ext = os.path.splitext(basename)\n",
    "                    random_name = uuid.uuid4().hex\n",
    "                    dest_filepath = os.path.join(os.path.dirname(dest_filepath), random_name + ext)\n",
    "\n",
    "                os.rename(source_filepath, dest_filepath)\n",
    "\n",
    "def count_files_in_directory(directory):\n",
    "    return sum([len(files) for _, _, files in os.walk(directory)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.lang_enum import TGLANG_LANGUAGE_EXTENSIONS\n",
    "\n",
    "GITHUB2TGLANG = {\n",
    "\n",
    "    # Other\n",
    "    # 'Markdown': 'TGLANG_LANGUAGE_MARKDOWN',\n",
    "    # 'JSON': 'TGLANG_LANGUAGE_JSON',\n",
    "    # 'CSV': 'TGLANG_LANGUAGE_CSV',\n",
    "\n",
    "    # Langsearch\n",
    "    # '1C Enterprise': 'TGLANG_LANGUAGE_1S_ENTERPRISE',\n",
    "    # 'ABAP': 'TGLANG_LANGUAGE_ABAP',\n",
    "    # 'HTML': 'TGLANG_LANGUAGE_HTML',\n",
    "    # 'QML': 'TGLANG_LANGUAGE_QML',\n",
    "    # 'YAML': 'TGLANG_LANGUAGE_YAML'\n",
    "    # 'Batchfile': 'TGLANG_LANGUAGE_BATCH',\n",
    "    # 'ASP': 'TGLANG_LANGUAGE_ASP',\n",
    "    # 'Dockerfile': 'TGLANG_LANGUAGE_DOCKER',\n",
    "    # 'Protocol Buffer': 'TGLANG_LANGUAGE_PROTOBUF',\n",
    "    # 'NGINX': 'TGLANG_LANGUAGE_NGINX',\n",
    "    # 'Solidity': 'TGLANG_LANGUAGE_SOLIDITY',\n",
    "    # 'GAMS': 'TGLANG_LANGUAGE_GAMS',\n",
    "    # 'AutoHotkey': 'TGLANG_LANGUAGE_AUTOHOTKEY',\n",
    "    # 'HACK': 'TGLANG_LANGUAGE_HACK',\n",
    "    # 'TypeScript': 'TGLANG_LANGUAGE_TYPESCRIPT',\n",
    "    # 'Verilog': 'TGLANG_LANGUAGE_VERILOG',\n",
    "    # 'PLSQL': 'TGLANG_LANGUAGE_PL_SQL',\n",
    "    # 'Makefile': 'TGLANG_LANGUAGE_MAKEFILE',\n",
    "    # 'Apex': 'TGLANG_LANGUAGE_APEX',\n",
    "    # 'Cpp': 'TGLANG_LANGUAGE_CPLUSPLUS',\n",
    "    # 'Python': 'TGLANG_LANGUAGE_PYTHON',\n",
    "    # 'JavaScript': 'TGLANG_LANGUAGE_JAVASCRIPT',\n",
    "    # 'C': 'TGLANG_LANGUAGE_C',\n",
    "    # 'Csharp': 'TGLANG_LANGUAGE_CSHARP',\n",
    "    # 'Java': 'TGLANG_LANGUAGE_JAVA',\n",
    "    # 'CSS': 'TGLANG_LANGUAGE_CSS',\n",
    "    # 'Go': 'TGLANG_LANGUAGE_GO',\n",
    "    # 'SQL': 'TGLANG_LANGUAGE_SQL',\n",
    "    # 'XML': 'TGLANG_LANGUAGE_XML',\n",
    "    # 'Rust': 'TGLANG_LANGUAGE_RUST',\n",
    "    # 'Shell': 'TGLANG_LANGUAGE_SHELL',\n",
    "    # 'Common Lisp': 'TGLANG_LANGUAGE_COMMON_LISP',\n",
    "    # 'IDL': 'TGLANG_LANGUAGE_IDL',\n",
    "    # 'Emacs Lisp': 'TGLANG_LANGUAGE_LISP',\n",
    "    # 'Assembly': 'TGLANG_LANGUAGE_ASSEMBLY',\n",
    "    # 'TeX': 'TGLANG_LANGUAGE_LATEX',\n",
    "    # 'Elm': 'TGLANG_LANGUAGE_ELM',\n",
    "    # 'OpenEdge ABL': 'TGLANG_LANGUAGE_OPENEDGE_ABL',\n",
    "    # 'Julia': 'TGLANG_LANGUAGE_JULIA',\n",
    "    # 'Fsharp': 'TGLANG_LANGUAGE_FSHARP',\n",
    "    # 'Objective-C': 'TGLANG_LANGUAGE_OBJECTIVE_C',\n",
    "    # 'PHP': 'TGLANG_LANGUAGE_PHP',\n",
    "    # 'PowerShell': 'TGLANG_LANGUAGE_POWERSHELL',\n",
    "    # 'ActionScript': 'TGLANG_LANGUAGE_ACTIONSCRIPT',\n",
    "    # 'Groovy': 'TGLANG_LANGUAGE_APACHE_GROOVY',\n",
    "    # 'Ada': 'TGLANG_LANGUAGE_ADA',\n",
    "    # 'AppleScript': 'TGLANG_LANGUAGE_APPLESCRIPT',\n",
    "    # 'BASIC': 'TGLANG_LANGUAGE_BASIC',\n",
    "    # 'AWK': 'TGLANG_LANGUAGE_AWK',\n",
    "    # 'Crystal': 'TGLANG_LANGUAGE_CRYSTAL',\n",
    "    # 'D': 'TGLANG_LANGUAGE_D',\n",
    "    # 'Dart': 'TGLANG_LANGUAGE_DART',\n",
    "    # 'Clojure': 'TGLANG_LANGUAGE_CLOJURE',\n",
    "    # 'COBOL': 'TGLANG_LANGUAGE_COBOL',\n",
    "    # 'Delphi': 'TGLANG_LANGUAGE_DELPHI',\n",
    "    # 'Elixir': 'TGLANG_LANGUAGE_ELIXIR',\n",
    "    # 'CoffeeScript': 'TGLANG_LANGUAGE_COFFESCRIPT',\n",
    "    # 'Erlang': 'TGLANG_LANGUAGE_ERLANG',\n",
    "    # 'Forth': 'TGLANG_LANGUAGE_FORTH',\n",
    "    # 'Fortran': 'TGLANG_LANGUAGE_FORTRAN',\n",
    "    # 'Haskell': 'TGLANG_LANGUAGE_HASKELL',\n",
    "    # 'Kotlin': 'TGLANG_LANGUAGE_KOTLIN',\n",
    "    # 'Lua': 'TGLANG_LANGUAGE_LUA',\n",
    "    # 'MATLAB': 'TGLANG_LANGUAGE_MATLAB',\n",
    "    # 'Nim': 'TGLANG_LANGUAGE_NIM',\n",
    "    # 'Pascal': 'TGLANG_LANGUAGE_PASCAL',\n",
    "    # 'OCaml': 'TGLANG_LANGUAGE_OCAML',\n",
    "    # 'R': 'TGLANG_LANGUAGE_R',\n",
    "    # 'Perl': 'TGLANG_LANGUAGE_PERL',\n",
    "    # 'Prolog': 'TGLANG_LANGUAGE_PROLOG',\n",
    "    # 'Ruby': 'TGLANG_LANGUAGE_RUBY',\n",
    "    # 'Scala': 'TGLANG_LANGUAGE_SCALA',\n",
    "    # 'Swift': 'TGLANG_LANGUAGE_SWIFT',\n",
    "    # 'Visual Basic .NET': 'TGLANG_LANGUAGE_VISUAL_BASIC',\n",
    "    # 'Scheme': 'TGLANG_LANGUAGE_SCHEME',\n",
    "    # 'SAS': 'TGLANG_LANGUAGE_SAS',\n",
    "    # 'Raku': 'TGLANG_LANGUAGE_RAKU',\n",
    "    # 'Smalltalk': 'TGLANG_LANGUAGE_SMALLTALK',\n",
    "    # 'Tcl': 'TGLANG_LANGUAGE_TCL',\n",
    "    # 'Vala': 'TGLANG_LANGUAGE_VALA',\n",
    "    # 'VBScript': 'TGLANG_LANGUAGE_VBSCRIPT',\n",
    "\n",
    "    # QSearch\n",
    "    # 'Gradle': 'TGLANG_LANGUAGE_GRADLE',\n",
    "    # 'GraphQL': 'TGLANG_LANGUAGE_GRAPHQL',\n",
    "    # 'Wolfram': 'TGLANG_LANGUAGE_WOLFRAM',\n",
    "    # 'TEXTILE': 'TGLANG_LANGUAGE_TEXTILE',\n",
    "    # 'INI': 'TGLANG_LANGUAGE_INI',\n",
    "    # 'Bison': 'TGLANG_LANGUAGE_BISON',\n",
    "    # 'Keyman': 'TGLANG_LANGUAGE_KEYMAN',\n",
    "    # 'Logo language': 'TGLANG_LANGUAGE_LOGO',\n",
    "    #'FUNC contract': 'TGLANG_LANGUAGE_FUNC',\n",
    "\n",
    "    ### Not processed\n",
    "\n",
    "    # QSearch\n",
    "    'TL Type Language': 'TGLANG_LANGUAGE_TL',\n",
    "    'FIFT TON': 'TGLANG_LANGUAGE_FIFT',\n",
    "    'Icon language': 'TGLANG_LANGUAGE_ICON',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT_REPOS = 500\n",
    "LIMIT_FILES = 20000 # it was different value for each language\n",
    "\n",
    "for github_lang in GITHUB2TGLANG.keys():\n",
    "    EXTENSIONS = TGLANG_LANGUAGE_EXTENSIONS[GITHUB2TGLANG[github_lang]]\n",
    "\n",
    "    # repos = get_repositories_for_language(github_lang, LIMIT_REPOS)\n",
    "    repos = get_repositories_for_query(github_lang, LIMIT_REPOS)\n",
    "\n",
    "    file_progress = tqdm.tqdm(total=LIMIT_FILES, desc=f\"Files ({github_lang})\", position=0, leave=True)\n",
    "\n",
    "    for repo in repos:\n",
    "        clone_and_process_repo(repo, github_lang, EXTENSIONS)\n",
    "\n",
    "        files_path = os.path.join('downloaded_files', github_lang)\n",
    "        num_files = count_files_in_directory(files_path)\n",
    "        file_progress.update(num_files - file_progress.n)\n",
    "        if num_files >= LIMIT_FILES:\n",
    "            break\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "import tqdm.autonotebook as tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from utils.lang_enum import languages\n",
    "\n",
    "DF_CACHE_PATH = \"../datasets/cache/all.pickle\"\n",
    "DF_PATHONLY_CACHE_PATH = \"../datasets/cache/path_only.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_files_content(root_dir, yaml_path):\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        mappings = yaml.safe_load(f)\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for language_tag, language_mapping in tqdm.tqdm(mappings.items()):\n",
    "        for language, extensions in language_mapping.items():\n",
    "            if not isinstance(extensions, list):\n",
    "                extensions = [extensions]\n",
    "\n",
    "            for extension in extensions:\n",
    "                lang_dir = os.path.join(root_dir, language)\n",
    "\n",
    "                if not os.path.exists(lang_dir):\n",
    "                    continue\n",
    "\n",
    "                for dirpath, dirnames, filenames in os.walk(lang_dir, followlinks=True):\n",
    "                    for filename in filenames:\n",
    "                        if extension == \".*\" or filename.endswith(extension):\n",
    "                            try:\n",
    "                                max_file_size = 4 * 1024 * 1024 # 4MB\n",
    "                                if os.path.getsize(os.path.join(dirpath, filename)) < max_file_size:\n",
    "                                    with open(os.path.join(dirpath, filename), 'r') as file:\n",
    "                                        content = file.read()\n",
    "                                        if len(content) > 0:\n",
    "                                            abs_path = os.path.abspath(os.path.join(dirpath, filename))\n",
    "                                            data_list.append((language_tag, language, content, abs_path))\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RosettaCodeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:03<00:00, 21.04it/s]\n"
     ]
    }
   ],
   "source": [
    "datafile = \"../datasets/RosettaCodeData/Conf/nlang.yaml\"\n",
    "dataroot = \"../datasets/RosettaCodeData/Lang\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "rosetta_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "rosetta_df[\"source\"] = \"rosetta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLLDCodeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 12.93it/s]\n"
     ]
    }
   ],
   "source": [
    "datafile = \"../datasets/deep-learning-lang-detection/data/nlang.yaml\"\n",
    "dataroot = \"../datasets/deep-learning-lang-detection/data/all\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "dlld_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "dlld_df[\"source\"] = \"dlld\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHubCodeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:56<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "datafile = \"../datasets/downloaded_files/nlang.yaml\"\n",
    "dataroot = \"../datasets/downloaded_files/\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "github_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "github_df[\"source\"] = \"github\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.71it/s]\n"
     ]
    }
   ],
   "source": [
    "datafile = \"../datasets/generated/nlang.yaml\"\n",
    "dataroot = \"../datasets/generated/\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "gen_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "gen_df[\"source\"] = \"generated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stackoverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n"
     ]
    }
   ],
   "source": [
    "datafile = \"../datasets/stackoverflow/nlang.yaml\"\n",
    "dataroot = \"../datasets/stackoverflow/\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "stack_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "stack_df[\"source\"] = \"stackoverflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 3053.36it/s]\n"
     ]
    }
   ],
   "source": [
    "datafile = \"../datasets/overfit/nlang.yaml\"\n",
    "dataroot = \"../datasets/overfit/\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "overfit_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "overfit_df[\"source\"] = \"overfit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2,154,545\n",
      "Memory usage: 22.29 GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([rosetta_df, dlld_df, github_df, gen_df, stack_df, overfit_df], ignore_index=True)\n",
    "print(f\"Number of samples: {len(df):,}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum()/1024/1024/1024:.2f} GB\")\n",
    "\n",
    "# Number of samples: 2,025,423\n",
    "# Memory usage: 22.21 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               language    code    path  source\n",
      "language_tag                                                   \n",
      "TGLANG_LANGUAGE_KEYMAN              115     115     115     115\n",
      "TGLANG_LANGUAGE_TEXTILE             127     127     127     127\n",
      "TGLANG_LANGUAGE_REGEX               824     824     824     824\n",
      "TGLANG_LANGUAGE_LOGO                982     982     982     982\n",
      "TGLANG_LANGUAGE_BISON              1101    1101    1101    1101\n",
      "TGLANG_LANGUAGE_WOLFRAM            1627    1627    1627    1627\n",
      "TGLANG_LANGUAGE_1S_ENTERPRISE      1681    1681    1681    1681\n",
      "TGLANG_LANGUAGE_ICON               1770    1770    1770    1770\n",
      "TGLANG_LANGUAGE_FUNC               3092    3092    3092    3092\n",
      "TGLANG_LANGUAGE_FIFT               3166    3166    3166    3166\n",
      "TGLANG_LANGUAGE_HACK               3403    3403    3403    3403\n",
      "TGLANG_LANGUAGE_NGINX              3437    3437    3437    3437\n",
      "TGLANG_LANGUAGE_INI                3831    3831    3831    3831\n",
      "TGLANG_LANGUAGE_APPLESCRIPT        3838    3838    3838    3838\n",
      "TGLANG_LANGUAGE_AWK                4599    4599    4599    4599\n",
      "TGLANG_LANGUAGE_VBSCRIPT           5103    5103    5103    5103\n",
      "TGLANG_LANGUAGE_CSV                5450    5450    5450    5450\n",
      "TGLANG_LANGUAGE_GRAPHQL            5534    5534    5534    5534\n",
      "TGLANG_LANGUAGE_ASP                5641    5641    5641    5641\n",
      "TGLANG_LANGUAGE_LISP               7154    7154    7154    7154\n",
      "TGLANG_LANGUAGE_GRADLE             7522    7522    7522    7522\n",
      "TGLANG_LANGUAGE_PROLOG             7727    7727    7727    7727\n",
      "TGLANG_LANGUAGE_LATEX              7742    7742    7742    7742\n",
      "TGLANG_LANGUAGE_RAKU               8057    8057    8057    8057\n",
      "TGLANG_LANGUAGE_BATCH              8508    8508    8508    8508\n",
      "TGLANG_LANGUAGE_COBOL              9081    9081    9081    9081\n",
      "TGLANG_LANGUAGE_APEX               9445    9445    9445    9445\n",
      "TGLANG_LANGUAGE_MAKEFILE           9826    9826    9826    9826\n",
      "TGLANG_LANGUAGE_TL                10051   10051   10051   10051\n",
      "TGLANG_LANGUAGE_COFFESCRIPT       11360   11360   11360   11360\n",
      "TGLANG_LANGUAGE_HTML              14077   14077   14077   14077\n",
      "TGLANG_LANGUAGE_GAMS              14262   14262   14262   14262\n",
      "TGLANG_LANGUAGE_PROTOBUF          15264   15264   15264   15264\n",
      "TGLANG_LANGUAGE_SAS               15534   15534   15534   15534\n",
      "TGLANG_LANGUAGE_AUTOHOTKEY        15798   15798   15798   15798\n",
      "TGLANG_LANGUAGE_BASIC             16186   16186   16186   16186\n",
      "TGLANG_LANGUAGE_SQL               16560   16560   16560   16560\n",
      "TGLANG_LANGUAGE_CSS               16868   16868   16868   16868\n",
      "TGLANG_LANGUAGE_OBJECTIVE_C       17013   17013   17013   17013\n",
      "TGLANG_LANGUAGE_NIM               17161   17161   17161   17161\n",
      "TGLANG_LANGUAGE_SHELL             17318   17318   17318   17318\n",
      "TGLANG_LANGUAGE_FORTH             17425   17425   17425   17425\n",
      "TGLANG_LANGUAGE_PL_SQL            17549   17549   17549   17549\n",
      "TGLANG_LANGUAGE_OPENEDGE_ABL      17744   17744   17744   17744\n",
      "TGLANG_LANGUAGE_QML               17933   17933   17933   17933\n",
      "TGLANG_LANGUAGE_VALA              17963   17963   17963   17963\n",
      "TGLANG_LANGUAGE_R                 18330   18330   18330   18330\n",
      "TGLANG_LANGUAGE_VISUAL_BASIC      18940   18940   18940   18940\n",
      "TGLANG_LANGUAGE_DELPHI            19152   19152   19152   19152\n",
      "TGLANG_LANGUAGE_CMAKE             19175   19175   19175   19175\n",
      "TGLANG_LANGUAGE_ABAP              19279   19279   19279   19279\n",
      "TGLANG_LANGUAGE_ELM               19404   19404   19404   19404\n",
      "TGLANG_LANGUAGE_TCL               19504   19504   19504   19504\n",
      "TGLANG_LANGUAGE_MATLAB            19524   19524   19524   19524\n",
      "TGLANG_LANGUAGE_PASCAL            19911   19911   19911   19911\n",
      "TGLANG_LANGUAGE_DART              20163   20163   20163   20163\n",
      "TGLANG_LANGUAGE_ERLANG            20527   20527   20527   20527\n",
      "TGLANG_LANGUAGE_SWIFT             20568   20568   20568   20568\n",
      "TGLANG_LANGUAGE_COMMON_LISP       20812   20812   20812   20812\n",
      "TGLANG_LANGUAGE_ELIXIR            20815   20815   20815   20815\n",
      "TGLANG_LANGUAGE_OCAML             20831   20831   20831   20831\n",
      "TGLANG_LANGUAGE_APACHE_GROOVY     20851   20851   20851   20851\n",
      "TGLANG_LANGUAGE_SCHEME            20901   20901   20901   20901\n",
      "TGLANG_LANGUAGE_LUA               20942   20942   20942   20942\n",
      "TGLANG_LANGUAGE_KOTLIN            21146   21146   21146   21146\n",
      "TGLANG_LANGUAGE_ADA               21186   21186   21186   21186\n",
      "TGLANG_LANGUAGE_ACTIONSCRIPT      21218   21218   21218   21218\n",
      "TGLANG_LANGUAGE_CRYSTAL           21264   21264   21264   21264\n",
      "TGLANG_LANGUAGE_JULIA             21503   21503   21503   21503\n",
      "TGLANG_LANGUAGE_PERL              21688   21688   21688   21688\n",
      "TGLANG_LANGUAGE_HASKELL           22099   22099   22099   22099\n",
      "TGLANG_LANGUAGE_IDL               22410   22410   22410   22410\n",
      "TGLANG_LANGUAGE_FSHARP            23080   23080   23080   23080\n",
      "TGLANG_LANGUAGE_FORTRAN           23199   23199   23199   23199\n",
      "TGLANG_LANGUAGE_SMALLTALK         23266   23266   23266   23266\n",
      "TGLANG_LANGUAGE_POWERSHELL        23695   23695   23695   23695\n",
      "TGLANG_LANGUAGE_PHP               23779   23779   23779   23779\n",
      "TGLANG_LANGUAGE_CLOJURE           23926   23926   23926   23926\n",
      "TGLANG_LANGUAGE_RUBY              24574   24574   24574   24574\n",
      "TGLANG_LANGUAGE_SCALA             24657   24657   24657   24657\n",
      "TGLANG_LANGUAGE_DOCKER            26225   26225   26225   26225\n",
      "TGLANG_LANGUAGE_D                 28250   28250   28250   28250\n",
      "TGLANG_LANGUAGE_ASSEMBLY          28913   28913   28913   28913\n",
      "TGLANG_LANGUAGE_XML               29076   29076   29076   29076\n",
      "TGLANG_LANGUAGE_YAML              38923   38923   38923   38923\n",
      "TGLANG_LANGUAGE_SOLIDITY          40190   40190   40190   40190\n",
      "TGLANG_LANGUAGE_TYPESCRIPT        40550   40550   40550   40550\n",
      "TGLANG_LANGUAGE_RUST              41050   41050   41050   41050\n",
      "TGLANG_LANGUAGE_PYTHON            41427   41427   41427   41427\n",
      "TGLANG_LANGUAGE_C                 41459   41459   41459   41459\n",
      "TGLANG_LANGUAGE_VERILOG           43892   43892   43892   43892\n",
      "TGLANG_LANGUAGE_CPLUSPLUS         44435   44435   44435   44435\n",
      "TGLANG_LANGUAGE_JAVA              44745   44745   44745   44745\n",
      "TGLANG_LANGUAGE_JAVASCRIPT        45241   45241   45241   45241\n",
      "TGLANG_LANGUAGE_GO                45550   45550   45550   45550\n",
      "TGLANG_LANGUAGE_CSHARP            49373   49373   49373   49373\n",
      "TGLANG_LANGUAGE_JSON              57405   57405   57405   57405\n",
      "TGLANG_LANGUAGE_MARKDOWN          64280   64280   64280   64280\n",
      "TGLANG_LANGUAGE_UNREALSCRIPT      65160   65160   65160   65160\n",
      "TGLANG_LANGUAGE_OTHER            199633  199633  199633  199633\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(\"language_tag\").count().sort_values(by=\"code\", ascending=True).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../datasets/cache/all.pickle\n",
      "Saved to ../datasets/cache/path_only.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(df, open(DF_CACHE_PATH, \"wb\"))\n",
    "print(f\"Saved to {DF_CACHE_PATH}\")\n",
    "\n",
    "pickle.dump(df[[\"language_tag\", \"language\", \"path\", \"source\"]], open(DF_PATHONLY_CACHE_PATH, \"wb\"))\n",
    "print(f\"Saved to {DF_PATHONLY_CACHE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.load(open(DF_PATHONLY_CACHE_PATH, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm.autonotebook as tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "def read_files_to_string(path, splitter='\\n'):\n",
    "    content = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            with open(filepath, 'r', errors='replace') as file:\n",
    "                content.append(file.read())\n",
    "\n",
    "    all_content = splitter.join(content)\n",
    "    no_empty_lines = splitter.join([line for line in all_content.split(splitter) if line.strip()])\n",
    "\n",
    "    return no_empty_lines.split(splitter)\n",
    "\n",
    "def generate_random_files(strings, output_path, num_files, k=100, header=\"\"):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    for i in tqdm.tqdm(range(num_files)):\n",
    "        random_selection = random.choices(strings, k=k)\n",
    "\n",
    "        file_name = f\"output_file_{i+1}.txt\"\n",
    "        file_path = os.path.join(output_path, file_name)\n",
    "\n",
    "        with open(file_path, 'w') as file:\n",
    "            if header:\n",
    "                file.write(header + \"\\n\")\n",
    "            for line in random_selection:\n",
    "                file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TL Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1051/10000 [00:00<00:00, 10502.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 11532.93it/s]\n"
     ]
    }
   ],
   "source": [
    "path_to_folder = '../datasets/downloaded_files/TL Type Language'\n",
    "result = read_files_to_string(path_to_folder)\n",
    "\n",
    "output_path = '../datasets/generated/TL Type Language'\n",
    "generate_random_files(result, output_path, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate FIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 14930.17it/s]\n"
     ]
    }
   ],
   "source": [
    "path_to_folder = '../datasets/generated/custom_fift'\n",
    "result = read_files_to_string(path_to_folder, splitter='\\n---')\n",
    "\n",
    "output_path = '../datasets/generated/FIFT TON'\n",
    "generate_random_files(result, output_path, 3000, k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate FUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 8415.59it/s]\n"
     ]
    }
   ],
   "source": [
    "path_to_folder = '../datasets/generated/custom_func'\n",
    "result = read_files_to_string(path_to_folder, splitter='\\n---')\n",
    "\n",
    "output_path = '../datasets/generated/FUNC contract'\n",
    "generate_random_files(result, output_path, 3000, k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse StackOverflow Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382512/1005750901.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  import tqdm.autonotebook as tqdm\n",
      "Comments:  99%|█████████▉| 89310000/90000000 [05:43<00:02, 263127.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of comments: 89,336\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm.autonotebook as tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "step = 1000\n",
    "filename = \"../datasets/stackoverflow/Comments.xml\"\n",
    "comments = []\n",
    "\n",
    "\n",
    "context = ET.iterparse(filename, events=(\"start\", \"end\"))\n",
    "context = iter(context)\n",
    "event, root = next(context)\n",
    "\n",
    "progress = tqdm.tqdm(total=90000000, desc=\"Comments\", position=0, leave=True)\n",
    "\n",
    "i = 0\n",
    "for event, elem in context:\n",
    "    if event == \"end\" and elem.tag == \"row\":\n",
    "        i += 1\n",
    "        if i % step == 0:\n",
    "            comments.append(elem.get('Text'))\n",
    "            progress.update(step)\n",
    "\n",
    "        elem.clear()\n",
    "\n",
    "del context\n",
    "\n",
    "print(f\"Number of comments: {len(comments):,}\")\n",
    "\n",
    "save_dir = \"../datasets/stackoverflow/other/comments\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for i, comment in enumerate(tqdm.tqdm(comments)):\n",
    "    with open(os.path.join(save_dir, f\"{i}.txt\"), \"w\") as f:\n",
    "        f.write(comment)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse StackOverflow Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm.autonotebook as tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import html\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "step = 1000\n",
    "total = 100000 * step\n",
    "offset = 40195000\n",
    "\n",
    "MIN_CODE_LEN = 50\n",
    "\n",
    "filename = \"../datasets/stackoverflow/Posts.xml\"\n",
    "def extract_code_and_other_from_body(body_text):\n",
    "    body_text = html.unescape(body_text)\n",
    "    pre_code_blocks = re.findall(r'<pre><code>(.*?)</code></pre>', body_text, re.DOTALL)\n",
    "    body_without_pre_code = re.sub(r'<pre><code>.*?</code></pre>', '', body_text, flags=re.DOTALL)\n",
    "    inline_code_blocks = re.findall(r'<code>([^<]+)</code>', body_without_pre_code)\n",
    "    non_code_text = re.sub(r'<code>[^<]+</code>', '', body_without_pre_code)\n",
    "    non_code_text = re.sub(r'<[^>]+>', '', non_code_text).strip()\n",
    "    all_code_blocks = pre_code_blocks + inline_code_blocks\n",
    "    return all_code_blocks, non_code_text\n",
    "\n",
    "def extract_tags(tags_str):\n",
    "    return set(tags_str[1:-1].split('><'))\n",
    "\n",
    "progress = tqdm.tqdm(total=total, desc=\"Posts\", position=0, leave=True)\n",
    "\n",
    "all_code = []\n",
    "all_tags = []\n",
    "all_other = []\n",
    "i = 0\n",
    "for event, elem in ET.iterparse(filename, events=('end',)):\n",
    "    if elem.tag == \"row\":\n",
    "        i += 1\n",
    "        if i < offset:\n",
    "            continue\n",
    "\n",
    "        if i % step == 0:\n",
    "            body = elem.attrib.get(\"Body\", \"\")\n",
    "            tags_str = elem.attrib.get(\"Tags\", \"\")\n",
    "            tags = extract_tags(tags_str)\n",
    "            code_blocks, other_text = extract_code_and_other_from_body(body)\n",
    "            for code in code_blocks:\n",
    "                if len(code) > MIN_CODE_LEN:\n",
    "                    all_code.append(code)\n",
    "                    all_tags.append(list(tags))\n",
    "            if other_text:\n",
    "                all_other.append(other_text)\n",
    "            elem.clear()\n",
    "\n",
    "            progress.update(step)\n",
    "\n",
    "            if i >= total:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39786"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you put the image in the same directory as the class file then the following should work for you:\n",
      "\n",
      "\n",
      "\n",
      "Also would suggest setting the icon image before you make the frame visible\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.choice(all_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'other' posts: 39,786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39786/39786 [00:01<00:00, 24327.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of 'other' posts: {len(all_other):,}\")\n",
    "save_dir = \"../datasets/stackoverflow/other/posts/0\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "for i, post in enumerate(tqdm.tqdm(all_other)):\n",
    "    with open(os.path.join(save_dir, f\"{i}.txt\"), \"w\") as f:\n",
    "        f.write(post)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
