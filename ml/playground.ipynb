{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from utils.lang_enum import languages\n",
    "\n",
    "DF_CACHE_PATH = \"../datasets/cache/all.pickle\"\n",
    "DF_PATHONLY_CACHE_PATH = \"../datasets/cache/path_only.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open(DF_CACHE_PATH, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby(\"language_tag\").count().sort_values(by=\"code\", ascending=True).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df[df.language_tag == \"TGLANG_LANGUAGE_OTHER\"].sample()\n",
    "print(s.language_tag.values[0])\n",
    "print(\"-\"*50)\n",
    "print(s.code.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train as mt\n",
    "\n",
    "MODEL_RESUME = \"./logs/2023-10-15_17-15-06_bs=512_epochs=1300/epoch=1114-step=781225.ckpt\"\n",
    "model = mt.LanguageClassifier.load_from_checkpoint(MODEL_RESUME, strict=False).cpu().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "DF_CACHE_PATH = \"../datasets/cache/all.pickle\"\n",
    "df = pickle.load(open(DF_CACHE_PATH, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TGLANG_LANGUAGE_OTHER', 'TGLANG_LANGUAGE_APACHE_GROOVY', 'TGLANG_LANGUAGE_1S_ENTERPRISE', 'TGLANG_LANGUAGE_ASSEMBLY', 'TGLANG_LANGUAGE_ABAP', 'TGLANG_LANGUAGE_ACTIONSCRIPT', 'TGLANG_LANGUAGE_ADA', 'TGLANG_LANGUAGE_APEX', 'TGLANG_LANGUAGE_APPLESCRIPT', 'TGLANG_LANGUAGE_BASIC', 'TGLANG_LANGUAGE_AWK', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_CMAKE', 'TGLANG_LANGUAGE_CLOJURE', 'TGLANG_LANGUAGE_COBOL', 'TGLANG_LANGUAGE_COFFESCRIPT', 'TGLANG_LANGUAGE_CRYSTAL', 'TGLANG_LANGUAGE_COMMON_LISP', 'TGLANG_LANGUAGE_D', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_DELPHI', 'TGLANG_LANGUAGE_ELIXIR', 'TGLANG_LANGUAGE_ELM', 'TGLANG_LANGUAGE_ERLANG', 'TGLANG_LANGUAGE_FORTH', 'TGLANG_LANGUAGE_FORTRAN', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_HACK', 'TGLANG_LANGUAGE_HASKELL', 'TGLANG_LANGUAGE_IDL', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_JULIA', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LATEX', 'TGLANG_LANGUAGE_LISP', 'TGLANG_LANGUAGE_LOGO', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_MAKEFILE', 'TGLANG_LANGUAGE_MATLAB', 'TGLANG_LANGUAGE_NIM', 'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_OCAML', 'TGLANG_LANGUAGE_OPENEDGE_ABL', 'TGLANG_LANGUAGE_PASCAL', 'TGLANG_LANGUAGE_PERL', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_PL_SQL', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_PROLOG', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_R', 'TGLANG_LANGUAGE_RAKU', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_SAS', 'TGLANG_LANGUAGE_SCALA', 'TGLANG_LANGUAGE_SCHEME', 'TGLANG_LANGUAGE_SMALLTALK', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_TCL', 'TGLANG_LANGUAGE_TYPESCRIPT', 'TGLANG_LANGUAGE_VALA', 'TGLANG_LANGUAGE_VBSCRIPT', 'TGLANG_LANGUAGE_VERILOG', 'TGLANG_LANGUAGE_VISUAL_BASIC', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_FSHARP', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_QML', 'TGLANG_LANGUAGE_YAML', 'TGLANG_LANGUAGE_BATCH', 'TGLANG_LANGUAGE_ASP', 'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_REGEX', 'TGLANG_LANGUAGE_PROTOBUF', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_GRADLE', 'TGLANG_LANGUAGE_GRAPHQL', 'TGLANG_LANGUAGE_WOLFRAM', 'TGLANG_LANGUAGE_TEXTILE', 'TGLANG_LANGUAGE_INI', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_FIFT', 'TGLANG_LANGUAGE_BISON', 'TGLANG_LANGUAGE_KEYMAN', 'TGLANG_LANGUAGE_GAMS', 'TGLANG_LANGUAGE_AUTOHOTKEY', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_MARKDOWN', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_CSV', 'TGLANG_LANGUAGE_ICON', 'TGLANG_LANGUAGE_UNREALSCRIPT']\n"
     ]
    }
   ],
   "source": [
    "print(df.language_tag.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et len: 366\n",
      "gt: TGLANG_LANGUAGE_C\n",
      "TGLANG_LANGUAGE_C: 0.81\n",
      "TGLANG_LANGUAGE_CPLUSPLUS: 0.01\n",
      "TGLANG_LANGUAGE_BISON: 0.01\n",
      "TGLANG_LANGUAGE_SCHEME: 0.00\n",
      "TGLANG_LANGUAGE_VALA: 0.00\n",
      "----------ORIGINAL TEXT----------\n",
      "  ADD_CNT (write);\n",
      "  START_TIMER (write);\n",
      "  if (server->sfd < 0) {\n",
      "    END_TIMER (write);\n",
      "    return -1;\n",
      "  }\n",
      "  int r = 0;\n",
      "  int first = 1;\n",
      "  \n",
      "  struct pollfd s;\n",
      "  s.fd = server->sfd;\n",
      "  s.events = POLLOUT;\n",
      "  static struct iovec t[3];\n",
      "  int ss, sf;\n",
      "  if (server->out_bytes) {\n",
      "    if (server->out_bytes != RPC_OUT_BUF_SIZE && server->out_rptr <= server->out_wptr) {\n",
      "      ss = 1;\n",
      "      t[1].iov_base = server->out_rptr;\n",
      "      t[1].iov_len = server->out_wptr - server->out_rptr;\n",
      "    } else {\n",
      "      ss = 0;\n",
      "      t[0].iov_base = server->out_rptr;\n",
      "      t[0].iov_len = server->out_buf + RPC_OUT_BUF_SIZE - server->out_rptr;\n",
      "      t[1].iov_base = server->out_buf;\n",
      "      t[1].iov_len = server->out_wptr - server->out_buf;\n",
      "    }\n",
      "  } else {\n",
      "    ss = 2;\n",
      "  }\n",
      "  if (buf && buf_len) {\n",
      "    sf = 3;\n",
      "    t[2].iov_base = buf;\n",
      "    t[2].iov_len = buf_len;\n",
      "  } else {\n",
      "    sf = 2;\n",
      "  }\n",
      "  if (!(sf - ss)) {\n",
      "    END_TIMER (write);\n",
      "    return 0; \n",
      "  }\n",
      "  int tt = 0;\n",
      "  do {\n",
      "    if (poll (&s, 1, tt) <= 0) {\n",
      "      if (first) {\n",
      "        first = 0;\n",
      "----------DECODED TOKENS----------\n",
      "add_<UNK> (write);\n",
      "start_timer (write);\n",
      "if (server-><UNK> < <UNK>) \n",
      "  end_timer (write);\n",
      "  return -<UNK>;\n",
      "}\n",
      "int <UNK> = <UNK>;\n",
      "struct <UNK>ol<UNK> <UNK>;\n",
      "<UNK>.<UNK> = server-><UNK>;\n",
      "<UNK>.events = <UNK>ol<UNK>out;\n",
      "static struct <UNK>vec <UNK>[<UNK>];\n",
      "int <UNK>, <UNK>;\n",
      "if (server->out_bytes) {\n",
      "    <UNK> =\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from utils import vocab\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from utils import helper, preprocess, lang_enum\n",
    "\n",
    "lang = random.choice(df.language_tag.unique().tolist())\n",
    "text = helper.augment(df[(df.language_tag == lang)].code.sample().iloc[0], lines_num_range=(5, 50))\n",
    "\n",
    "et = preprocess.encode_text(text)\n",
    "inputs = torch.tensor(et[:vocab.max_size])\n",
    "inputs = torch.cat([inputs, torch.zeros(vocab.max_size - len(inputs), dtype=torch.long)], dim=0).unsqueeze(0)\n",
    "r = model(inputs.long(), None).softmax(1)\n",
    "\n",
    "print(\"et len:\", len(et))\n",
    "print(\"gt:\", lang)\n",
    "top = 5\n",
    "t5 = r.topk(top)\n",
    "for i in range(top):\n",
    "    print(f\"{lang_enum.languages[t5.indices[0][i].item()]}: {t5.values[0][i].item():.2f}\")\n",
    "print(\"-\"*10 + \"ORIGINAL TEXT\" + \"-\"*10)\n",
    "print(text)\n",
    "print(\"-\"*10 + \"DECODED TOKENS\" + \"-\"*10)\n",
    "print(preprocess.decode_text(inputs.tolist()[0][:len(et)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run full ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import train as mt\n",
    "\n",
    "MODEL_RESUME = \"./logs/2023-10-14_16-11-14_bs=512_epochs=1100/epoch=1086-step=766482.ckpt\"\n",
    "model = mt.LanguageClassifier.load_from_checkpoint(MODEL_RESUME, strict=False)\n",
    "model = model.cuda().eval()\n",
    "\n",
    "pdf = pickle.load(open(DF_PATHONLY_CACHE_PATH, \"rb\"))\n",
    "dataset = mt.CodeDataset(pdf, aug=False)\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15698 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15698/15698 [12:45<00:00, 20.51it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm.autonotebook as tqdm\n",
    "\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "for batch in tqdm.tqdm(train_loader):\n",
    "    x, am, y = batch\n",
    "    y_hat = model(x.cuda(), am.cuda())\n",
    "\n",
    "    probs = y_hat.softmax(dim=1)\n",
    "    pred_labels = probs.argmax(dim=1)\n",
    "\n",
    "    for p, l in zip(probs, pred_labels):\n",
    "        all_preds.append(l.item())\n",
    "        all_probs.append(p[l].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pred\"] = all_preds\n",
    "df[\"prob\"] = all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = df[df.prob < 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12984"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT: TGLANG_LANGUAGE_GAMS\n",
      "PRED: TGLANG_LANGUAGE_INI 0.18\n",
      "--------------------------------------------------\n",
      "p_ng 641.0000085356635\n"
     ]
    }
   ],
   "source": [
    "from utils import lang_enum\n",
    "# lang = \"TGLANG_LANGUAGE_SWIFT\"\n",
    "lang = None\n",
    "s = tdf[tdf.pred_lang == lang].sample() if lang is not None else tdf.sample()\n",
    "\n",
    "print(\"GT:\", s.language_tag.values[0])\n",
    "print(\"PRED:\", lang_enum.languages[s.pred.values[0]], f\"{s.prob.values[0]:.2f}\")\n",
    "print(\"-\"*50)\n",
    "print(s.code.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE MODEL_META.HPP\n",
    "\n",
    "from utils import vocab\n",
    "\n",
    "def escape_string(s):\n",
    "    return s.replace('\\\\', '\\\\\\\\').replace('\\n', '\\\\n').replace('\\t', '\\\\t').replace('\"', r'\\\"')\n",
    "\n",
    "def generate_cpp_header(strings):\n",
    "    header_content = \"#pragma once\\n\\n\"\n",
    "    header_content += \"#include <vector>\\n\"\n",
    "    header_content += \"#include <unordered_map>\\n\"\n",
    "    header_content += \"#include <string>\\n\\n\"\n",
    "\n",
    "    max_len = max([len(s) for s in strings])\n",
    "    header_content += \"const int MODEL_MAX_INPUT = \" + str(vocab.max_size) + \";\\n\"\n",
    "    header_content += \"const float DETECTION_THRESHOLD = 0.2;\\n\"\n",
    "    header_content += \"const int MAX_LINE_LEN = \" + str(vocab.max_line_len) + \";\\n\"\n",
    "    header_content += \"const std::vector<int> SPACES_RANGE = {\" + f\"{vocab.spaces_range[0]}, {vocab.spaces_range[1]}\" + \"};\\n\"\n",
    "    header_content += \"const int LETTERS_POSE = \" + str(vocab.letters_pose) + \";\\n\"\n",
    "    header_content += \"const int VOCAB_NEW_LINE_ID = \" + str(vocab.vocab_dict[\"\\n\"]) + \";\\n\"\n",
    "    header_content += \"const int VOCAB_UNK_ID = \" + str(len(vocab.vocab_list) - 1) + \";\\n\"\n",
    "    header_content += \"const int VOCAB_PAD_ID = \" + str(len(vocab.vocab_list) - 2) + \";\\n\"\n",
    "    header_content += \"const int VOCAB_MAX_LEN = \" + str(max_len) + \";\\n\\n\"\n",
    "    header_content += \"using det_int_t = int64_t;\\n\\n\"\n",
    "\n",
    "    header_content += \"const std::vector<std::string> vocab_list = {\\n\"\n",
    "    for s in strings:\n",
    "        header_content += '    \"' + escape_string(s) + '\",\\n'\n",
    "    header_content += \"};\\n\\n\"\n",
    "\n",
    "    vocab_map = {s: i for i, s in enumerate(strings)}\n",
    "    header_content += \"const std::unordered_map<std::string, int> vocab_map = {\\n\"\n",
    "    for s, i in vocab_map.items():\n",
    "        header_content += '    {\"' + escape_string(s) + '\", ' + str(i) + '},\\n'\n",
    "    header_content += \"};\\n\\n\"\n",
    "\n",
    "    return header_content\n",
    "\n",
    "header = generate_cpp_header(vocab.vocab_list)\n",
    "with open(\"../lib/data/model/model_meta.hpp\", 'w') as f:\n",
    "    f.write(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train as mt\n",
    "\n",
    "MODEL_RESUME = \"./logs/2023-10-15_17-15-06_bs=512_epochs=1300/epoch=1114-step=781225.ckpt\"\n",
    "model = mt.LanguageClassifier.load_from_checkpoint(MODEL_RESUME, strict=False)\n",
    "model = model.cpu().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ./logs/2023-10-15_17-15-06_bs=512_epochs=1300/hfmodel\n"
     ]
    }
   ],
   "source": [
    "# SAVE MODEL TO HF\n",
    "\n",
    "import os\n",
    "save_path = os.path.join(os.path.dirname(MODEL_RESUME), \"hfmodel\")\n",
    "model.model.save_pretrained(save_path)\n",
    "print(f\"Saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO TFLITE AND SAVE\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import TFMobileBertForSequenceClassification\n",
    "\n",
    "from utils import lang_enum\n",
    "\n",
    "tfmodel = TFMobileBertForSequenceClassification.from_pretrained(save_path, from_pt=True)\n",
    "class TGInferenceModelKeras(tf.keras.Model):\n",
    "    def __init__(self, tfmodel):\n",
    "        super().__init__()\n",
    "        self.model = tfmodel\n",
    "        self.max_len = 256\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=[\n",
    "            tf.TensorSpec(\n",
    "                shape=[None],\n",
    "                dtype=tf.int64,\n",
    "                name=\"inputs\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    def call(self, inputs):\n",
    "        inputs = inputs[:self.max_len]\n",
    "        inputs = inputs[None]\n",
    "        logits = self.model(inputs).logits[0]\n",
    "        label = tf.argmax(logits, axis=-1)\n",
    "        conf = tf.nn.softmax(logits)[label]\n",
    "        return label, conf\n",
    "\n",
    "kerasmodel = TGInferenceModelKeras(tfmodel)\n",
    "\n",
    "inputs = tf.zeros(512, dtype=tf.int64)\n",
    "label, conf = kerasmodel(inputs)\n",
    "print(\"Label: \", lang_enum.languages[label.numpy()], \"Confidence: \", conf.numpy())\n",
    "\n",
    "### TO TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(kerasmodel)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "converter.experimental_new_converter = True\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "save_tf_lite_path = os.path.join(\n",
    "    os.path.dirname(MODEL_RESUME), os.path.basename(MODEL_RESUME).split(\".\")[0] + \".tflite\"\n",
    ")\n",
    "with open(save_tf_lite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Converting finished. Saved to: \", os.path.abspath(save_tf_lite_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp $save_tf_lite_path ../lib/data/model/model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serving_default': {'inputs': ['inputs'],\n",
       "  'outputs': ['output_1', 'output_2']}}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path=save_tf_lite_path)\n",
    "interpreter.get_signature_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
